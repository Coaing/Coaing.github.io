---
layout:     post
title:      Hadoop初识
subtitle:   Hadoop之初见Hadoop
date:       2019-09-02
author:     XU
header-img: img/post-bg-cook.jpg
catalog: 	 true
tags:
    - Hadoop
---

# 一、Hadoop概述
## 1.1 概念
HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。
HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。

## 1.2 Hadoop组成：

1）HDFS集群包括，NameNode和DataNode以及Secondary Namenode。

2）NameNode负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。

3）DataNode 负责管理用户的文件数据块，每一个数据块都可以在多个datanode上存储多个副本。

4）Secondary NameNode用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。

![Hadoop组成](https://github.com/codlx/codlx.github.io/blob/master/img/hadoop_com.png "Hadoop组成")


### 1.2.1 HDFS

HDFS架构概述：

1）NameNode(nn)存储文件的元数据，如文件名，文件目录结构，文件属性(生成时间，副本数，文件权限)，以及每个文件的块列表和块所在的DataNode等

2）DataNode(dn)在本地文件系统存储文件块数据，以及块数据的校验和

3）SecondaryNameNode(2nn)用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照

### 1.2.2 YARN

1）ResourceManager(rm)处理客户端请求，启动/监控ApplicationMaster，监控NodeManager，资源分配与调度

2）NodeManager(nm)单个节点上的资源管理，处理来自ResourceManager的命令、处理来自ApplicationMaster的命令

3）ApplicationMaster：数据切分，为应用程序申请资源，并分配给内部任务、任务监控与容错

4）Container：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息

### 1.2.3 MapReduce：

MapReduce将计算过程分为两个阶段:

1)Map阶段并行处理输入的数据

2)Reduce阶段对Map结果进行汇总

# 二、Hadoop运行环境搭建

## 2.1 本地机器修改hosts

## 2.2 虚拟化网络设置为NAT

## 2.3 克隆虚拟机

## 2.4 修改为静态ip：

`[root@hadoop101 /]#vim /etc/udev/rules.d/70-persistent-net.rules`

进入如下页面，删除eth0该行；将eth1修改为eth0，同时复制物理ip地址

![ip_cg1](https://github.com/codlx/codlx.github.io/blob/master/img/ip_cg1.png "ip_cg1")


### 2.4.1 修改IP地址

`[root@hadoop101 /]#vim /etc/sysconfig/network-scripts/ifcfg-eth0`

需要修改的内容有5项：

`IPADDR=192.168.1.101

GATEWAY=192.168.1.2

ONBOOT=yes

BOOTPROTO=static

DNS1=192.168.1.2`

#### 修改前

![ip_cg2](https://github.com/codlx/codlx.github.io/blob/master/img/ip_cg2.png "ip_cg2")


#### 修改后

#### 执行

`service network restart`


#### 如果报错，reboot，重启虚拟机


## 2.4 修改主机名

### 2.4.1 修改hostname

`vi /etc/sysconfig/network`

注意：主机名称不要有下划线

### 2.4.2

`vim /etc/hosts`

添加如下内容
192.168.1.100 hadoop100

192.168.1.101 hadoop101

192.168.1.102 hadoop102

192.168.1.103 hadoop103

192.168.1.104 hadoop104

192.168.1.105 hadoop105

192.168.1.106 hadoop106

192.168.1.107 hadoop107

192.168.1.108 hadoop108

192.168.1.109 hadoop109

192.168.1.110 hadoop110

可以多添加几个，后来在增加节点时，不用再修改hosts

### 2.4.3 本地机器修改hosts

C -> Windows -> System32 -> drivers -> etc

添加如下内容
192.168.1.100 hadoop100

192.168.1.101 hadoop101

192.168.1.102 hadoop102

192.168.1.103 hadoop103

192.168.1.104 hadoop104

192.168.1.105 hadoop105

192.168.1.106 hadoop106

192.168.1.107 hadoop107

192.168.1.108 hadoop108

192.168.1.109 hadoop109

192.168.1.110 hadoop110

## 2.5 关闭防火墙

1）查看防火墙开机启动状态

`chkconfig iptables --list`

2）关闭防火墙

`chkconfig iptables off`

## 2.6 在opt目录下创建文件(用户atguigu下)
## 2.6.1 创建atguigu用户

在root用户里面执行如下操作
```
[root@hadoop101 opt]# adduser atguigu
[root@hadoop101 opt]# passwd atguigu
```

### 2.6.2 设置atguigu用户具有root权限

修改 /etc/sudoers 文件，找到下面一行，在root下面添加一行，如下所示：

```
## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL
atguigu   ALL=(ALL)     ALL

```

修改完毕，现在可以用atguigu帐号登录

### 2.6.3 在/opt目录下创建文件夹

（1）在root用户下创建module、software文件夹

```
mkdir module
mkdir software

```

（2）修改module、software文件夹的所有者

```
[root@hadoop101 opt]# chown  module
[root@hadoop101 opt]# chown atguigu software
[root@hadoop101 opt]# ls -al

```

## 2.7 安装jdk

1）卸载现有jdk

 （1）查询是否安装java软件：

     rpm -qa|grep java

（2）如果安装的版本低于1.7，卸载该jdk：

    rpm -e 软件包

2）用filezilla工具将jdk、Hadoop-2.7.2.tar.gz导入到opt目录下面的software文件夹下面

3）在linux系统下的opt目录中查看软件包是否导入成功

```
[root@hadoop101opt]# cd software/

[root@hadoop101software]# ls

jdk-7u79-linux-x64.gz  hadoop-2.7.2.tar.gz  
```  

4）解压jdk到/opt/module目录下

	tar -zxf jdk-7u79-linux-x64.gz -C /opt/module/

5）配置jdk环境变量

 （1）先获取jdk路径：
 ```
 [root@hadoop101 jdk1.7.0_79]# pwd
 /opt/module/jdk1.7.0_79
 ```

 2）打开/etc/profile文件：
```
[root@hadoop101 jdk1.7.0_79]# vi /etc/profile
```
在profie文件末尾添加jdk路径：

```
##JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.7.0_79
export PATH=$PATH:$JAVA_HOME/bin

```
 （3）保存后退出：`:wq`

 （4）让修改后的文件生效：

` [root@hadoop101 jdk1.7.0_79]# source  /etc/profile`

 （5）重启（如果java –version可以用就不用重启）：

  ```
  [root@hadoop101 jdk1.7.0_79]# sync
  [root@hadoop101 jdk1.7.0_79]# reboot

  ```


  6）测试jdk安装成功
  ```
  [root@hadoop101 jdk1.7.0_79]# java -version
  java version "1.7.0_79"

  ```

## 2.8 安装Hadoop

1）进入到Hadoop安装包路径下：

[root@hadoop101 ~]# cd /opt/software/

2）解压安装文件到/opt/module下面

[root@hadoop101 software]# tar -zxf hadoop-2.7.2.tar.gz -C /opt/module/

3）查看是否解压成功

[root@hadoop101 software]# ls /opt/module/

hadoop-2.7.2  

4）配置hadoop中的hadoop-env.sh

（1）Linux系统中获取jdk的安装路径：

```
[root@hadoop101 jdk1.7.0_79]# echo $JAVA_HOME
/opt/module/jdk1.7.0_79
```
（2）修改hadoop-env.sh文件中JAVA_HOME 路径：

```
export JAVA_HOME=/opt/module/jdk1.7.0_79
```
5）将hadoop添加到环境变量

  （1）获取hadoop安装路径：

```  
[root@ hadoop101 hadoop-2.7.2]# pwd
  /opt/module/hadoop-2.7.2
```

（2）打开/etc/profile文件：

`root@ hadoop101 hadoop-2.7.2]# vi /etc/profile`

在profie文件末尾添加HADOOP_HOME路径：

```
##HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-2.7.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

```
（3）保存后退出：

  `:wq`

（4）让修改后的文件生效：
`root@ hadoop101 hadoop-2.7.2]# source /etc/profile`

（5）重启(如果hadoop命令不能用再重启)
  ```
    root@ hadoop101 hadoop-2.7.2]# sync
    root@ hadoop101 hadoop-2.7.2]# reboot

  ```

# 三、Hadoop运行模式

  1）官方网址

  （1）官方网站：

    http://hadoop.apache.org/

  （2）各个版本归档库地址

    https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/

  （3）hadoop2.7.2版本详情介绍

    http://hadoop.apache.org/docs/r2.7.2/

  2）Hadoop运行模式

  （1）本地模式（默认模式）：

  不需要启用单独进程，直接可以运行，测试和开发时使用。

  （2）伪分布式模式：

  等同于完全分布式，只有一个节点。

  （3）完全分布式模式：

  多个节点一起运行。

## 3.1 本地文件运行Hadoop 案例
### 3.1.1 官方grep案例
  1）创建在hadoop-2.7.2文件下面创建一个input文件夹

  `[atguigu@hadoop101 hadoop-2.7.2]$mkdir input`

  2）将hadoop的xml配置文件复制到input

  `[atguigu@hadoop101 hadoop-2.7.2]$cp etc/hadoop/*.xml input`

  3）执行share目录下的mapreduce程序

  `[atguigu@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'`

  4）查看输出结果

  `[atguigu@hadoop101 hadoop-2.7.2]$ cat output/*`

### 3.1.2 官方wordcount案例

  1）创建在hadoop-2.7.2文件下面创建一个wcinput文件夹

  `[atguigu@hadoop101 hadoop-2.7.2]$mkdir wcinput`

  2）在wcinput文件下创建一个wc.input文件

  ```
  [atguigu@hadoop101 hadoop-2.7.2]$cd wcinput
  [atguigu@hadoop101 wcinput]$touch wc.input
  ```

  3）编辑wc.input文件

  `[atguigu@hadoop101 wcinput]$vim wc.input`

  在文件中输入如下内容

  ```
  hadoop yarn
  hadoop mapreduce
  atguigu
  atguigu
```
  保存退出：：wq

  4）回到hadoop目录/opt/module/hadoop-2.7.2

  5）执行程序：

  ```
  [atguigu@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput
  ```
  6）查看结果：

  ```
  [atguigu@hadoop101 hadoop-2.7.2]$cat wcoutput/part-r-00000

  atguigu 2
  hadoop  2
  mapreduce       1
  yarn    1

  ```

## 3.2 伪分布式运行Hadoop 案例
### 3.2.1 HDFS上运行MapReduce 程序

  1）分析：

（1）准备1台客户机

（2）安装jdk

（3）配置环境变量

（4）安装hadoop

（5）配置环境变量

（6）配置集群

（7）启动、测试集群增、删、查

（8）在HDFS上执行wordcount案例

2）执行步骤

需要配置hadoop文件如下

（1）配置集群

  （a）配置：hadoop-env.sh

  Linux系统中获取jdk的安装路径：

  `[root@ hadoop101 ~]# echo $JAVA_HOME
  /opt/module/jdk1.7.0_79`

修改JAVA_HOME 路径：

  `export JAVA_HOME=/opt/module/jdk1.7.0_79`

  （b）配置：core-site.xml

  ```
  <!-- 指定HDFS中NameNode的地址 -->
  <property>
  <name>fs.defaultFS</name>
  <value>hdfs://hadoop101:9000</value>
  </property>

  <!-- 指定hadoop运行时产生文件的存储目录 -->
  <property>
  <name>hadoop.tmp.dir</name>
  <value>/opt/module/hadoop-2.7.2/data/tmp</value>
  </property>

  ```

（c）配置：hdfs-site.xml  

  ```
  <!-- 指定HDFS副本的数量 -->
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>

  ```

  （2）启动集群

（a）格式化namenode（第一次启动时格式化，以后就不要总格式化）

`bin/hdfs namenode -format`

（b）启动namenode

sbin/hadoop-daemon.sh start namenode

（c）启动datanode

sbin/hadoop-daemon.sh start datanode

（3）查看集群

（a）查看是否启动成功
```    
[root@hadoop101 ~]# jps
13586 NameNode
13668 DataNode
13786 Jps
```
（b）查看产生的log日志

当前目录：/opt/module/hadoop-2.7.2/logs
```  
[root@hadoop101 logs]# ls
hadoop-root-datanode-hadoop.atguigu.com.log
hadoop-root-datanode-hadoop.atguigu.com.out
hadoop-root-namenode-hadoop.atguigu.com.log
hadoop-root-namenode-hadoop.atguigu.com.out
SecurityAuth-root.audit

[root@hadoop101 logs]# cat hadoop-root-datanode-hadoop.atguigu.com.log

```

（c）web端查看HDFS文件系统

http://192.168.1.101:50070/dfshealth.html#tab-overview

注意：如果不能查看，看如下帖子处理

http://www.cnblogs.com/zlslch/p/6604189.html

（4）操作集群
（a）在hdfs文件系统上创建一个input文件夹

`[atguigu@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -mkdir -p /user/atguigu/mapreduce/wordcount/input`

（b）将测试文件内容上传到文件系统上

`bin/hdfs dfs -put wcinput/wc.input  /user/atguigu/mapreduce/wordcount/input/`

（c）查看上传的文件是否正确
```    
bin/hdfs dfs -ls  /user/atguigu/mapreduce/wordcount/input/
bin/hdfs dfs -cat  /user/atguigu/mapreduce/wordcount/input/wc.input
```
（d）在Hdfs上运行mapreduce程序

`	bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/mapreduce/wordcount/input/ /user/atguigu/mapreduce/wordcount/output`

（e）查看输出结果

命令行查看：

`  bin/hdfs dfs -cat /user/atguigu/mapreduce/wordcount/output/*`

浏览器查看

（f）将测试文件内容下载到本地

`hadoop fs -get /user/atguigu/mapreduce/wordcount/output/part-r-00000 ./wcoutput/
`
（g）删除输出结果

`  hdfs dfs -rmr /user/atguigu/mapreduce/wordcount/output`

### 3.2.2 YARN上运行MapReduce 程序
1）分析：

（1）准备1台客户机

（2）安装jdk

（3）配置环境变量

（4）安装hadoop

（5）配置环境变量

（6）配置集群yarn上运行

（7）启动、测试集群增、删、查

（8）在yarn上执行wordcount案例

2）执行步骤

（1）配置集群

a）配置yarn-env.sh

配置一下JAVA_HOME

`export JAVA_HOME=/opt/module/jdk1.7.0_79`

（b）配置yarn-site.xml

```
<!-- reducer获取数据的方式 -->
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>

<!-- 指定YARN的ResourceManager的地址 -->
<property>
<name>yarn.resourcemanager.hostname</name>
<value>hadoop101</value>
</property>

```

（c）配置：mapred-env.sh

配置一下JAVA_HOME

`export JAVA_HOME=/opt/module/jdk1.7.0_79`

（d）配置： (对mapred-site.xml.template重新命名为) mapred-site.xml

```
<!-- 指定mr运行在yarn上 -->
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>

```

（2）启动集群

（a）启动resourcemanager

`  sbin/yarn-daemon.sh start resourcemanager
`
（b）启动nodemanager

`sbin/yarn-daemon.sh start nodemanager`

（3）集群操作

（a）yarn的浏览器页面查看

http://192.168.1.101:8088/cluster


（b）删除文件系统上的output文件,output不能是已经存在的目录

`bin/hdfs dfs -rm -R /user/atguigu/mapreduce/wordcount/output`

（c）执行mapreduce程序
```
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/mapreduce/wordcount/input  /user/atguigu/mapreduce/wordcount/output
```
（d）查看运行结果

`  bin/hdfs dfs -cat /user/atguigu/mapreduce/wordcount/output/*`

### 3.2.3 修改本地临时文件存储目录

1）停止进程

```
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop resourcemanager
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop namenode

```

2）修改hadoop.tmp.dir

[core-site.xml]

```
<!-- 指定hadoop运行时产生文件的存储目录 -->
<property>
<name>hadoop.tmp.dir</name>
<value>/opt/module/hadoop-2.7.2/data/tmp</value>
</property>

```

3）格式化NameNode

`[atguigu@hadoop101 hadoop-2.7.2]$ hadoop namenode -format`

4）启动所有进程

```
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start resourcemanager
[atguigu@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager

```

5）查看/opt/module/hadoop-2.7.2/data/tmp这个目录下的内容

### 3.2.4 Hadoop配置文件说明

Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。

（1）默认配置文件：存放在hadoop相应的jar包中

```  
[core-default.xml]
hadoop-common-2.7.2.jar/ core-default.xml
[hdfs-default.xml]
hadoop-hdfs-2.7.2.jar/ hdfs-default.xml
[yarn-default.xml]
hadoop-yarn-common-2.7.2.jar/ yarn-default.xml
[core-default.xml]
hadoop-mapreduce-client-core-2.7.2.jar/ core-default.xml

```

（2）自定义配置文件：存放在$HADOOP_HOME/etc/hadoop
```
core-site.xml
hdfs-site.xml
yarn-site.xml
mapred-site.xml

```

### 3.2.5 历史服务配置启动查看   


1）配置mapred-site.xml

```
<property>
<name>mapreduce.jobhistory.address</name>
<value>hadoop101:10020</value>
</property>
<property>
<name>mapreduce.jobhistory.webapp.address</name>
<value>hadoop101:19888</value>
</property>

```
2）查看启动历史服务器文件目录：

```
[root@hadoop101 hadoop-2.7.2]# ls sbin/ |grep mr
mr-jobhistory-daemon.sh

```

3）启动历史服务器

sbin/mr-jobhistory-daemon.sh start historyserver

4）查看历史服务器是否启动

jps

5）查看jobhistory

http://192.168.1.101:19888/jobhistory

### 3.2.6 日志的聚集

日志聚集概念：应用运行完成以后，将日志信息上传到HDFS系统上

开启日志聚集功能步骤：

（1）配置yarn-site.xml

```
<!-- 日志聚集功能使能 -->
<property>
<name>yarn.log-aggregation-enable</name>
<value>true</value>
</property>
<!-- 日志保留时间设置7天 -->
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>604800</value>
</property>

```


（2）关闭nodemanager 、resourcemanager和historymanager
```
sbin/yarn-daemon.sh stop resourcemanager
sbin/yarn-daemon.sh stop nodemanager
sbin/mr-jobhistory-daemon.sh stop historyserver
```
（3）启动nodemanager 、resourcemanager和historymanager
```
sbin/yarn-daemon.sh start resourcemanager
sbin/yarn-daemon.sh start nodemanager
sbin/mr-jobhistory-daemon.sh start historyserver
```
（4）删除hdfs上已经存在的hdfs文件

`bin/hdfs dfs -rm -R /user/atguigu/mapreduce/wordcount/output`

（5）执行wordcount程序
```      
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount /user/atguigu/mapreduce/wordcount/input /user/atguigu/mapreduce/wordcount/output
```
（6）查看日志

http://192.168.1.101:19888/jobhistory


## 3.3 完全分布式部署Hadoop

分析：

1）准备3台客户机（关闭防火墙、静态ip、主机名称）

2）安装jdk

3）配置环境变量

4）安装hadoop

5）配置环境变量

6）安装ssh

7）配置集群

8）启动测试集群

3.3.1 虚拟机准备

(详见2.2-2.3)

3.3.2 主机名设置

(详见2.4)

3.3.3 scp

1）scp可以实现服务器与服务器之间的数据拷贝

2）案例实操

（1）将hadoop101中/opt/module和/opt/software文件拷贝到hadoop102、hadoop103和hadoop104上
```  
[root@hadoop101 /]# scp -r /opt/module/  root@hadoop102:/opt
[root@hadoop101 /]# scp -r /opt/software/  root@hadoop102:/opt
[root@hadoop101 /]# scp -r /opt/module/  root@hadoop103:/opt
[root@hadoop101 /]# scp -r /opt/software/  root@hadoop103:/opt
[root@hadoop101 /]# scp -r /opt/module/  root@hadoop104:/opt
[root@hadoop101 /]# scp -r /opt/software/  root@hadoop105:/opt
```
（2）将192.168.1.102服务器上的文件拷贝到当前用户下

` [root@hadoop101 opt]# scp  root@hadoop102:/etc/profile  /opt/tmp/`

（3）实现两台远程机器之间的文件传输（hadoop103主机文件拷贝到hadoop104主机上）

`  [atguigu@hadoop102 test]$ scp atguigu@hadoop103:/opt/test/haha atguigu@hadoop104:/opt/test/`


### 3.3.4 SSH无密码登录

1）配置ssh

（1）基本语法

ssh 另一台电脑的ip地址

（2）ssh连接时出现Host key verification failed的解决方法
```  
[root@hadoop2 opt]# ssh 192.168.1.103

The authenticity of host '192.168.1.103 (192.168.1.103)' can't be established.
RSA key fingerprint is cf:1e:de:d7:d0:4c:2d:98:60:b4:fd:ae:b1:2d:ad:06.
Are you sure you want to continue connecting (yes/no)?
Host key verification failed.
```
（3）解决方案如下：直接输入yes

2）无密钥配置

（1）进入到我的home目录

`cd  ~/.ssh`

（2）生成公钥和私钥：

`ssh-keygen -t rsa `

然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

（3）将公钥拷贝到要免密登录的目标机器上

`ssh-copy-id 192.168.1.102`

3）.ssh文件夹下的文件功能解释

（1）~/.ssh/known_hosts	：记录ssh访问过计算机的公钥(public key)

（2）id_rsa	：生成的私钥

（3）id_rsa.pub	：生成的公钥

（4）authorized_keys	：存放授权过得无秘登录服务器公钥


![rsa](https://github.com/codlx/codlx.github.io/blob/master/img/rsa.png "rsa")

### 3.3.5 rsync

rsync远程同步工具，主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点

（1）查看rsync使用说明

man rsync | more

（2）基本语法

rsync -rvl     $pdir/$fname         $user@hadoop$host:$pdir

命令 命令参数 要拷贝的文件路径/名称   目的用户@主机:目的路径

选项

-r 递归

-v 显示复制过程

-l 拷贝符号连接

（3）案例实操

把本机/opt/tmp目录同步到hadoop103服务器的root用户下的/opt/tmp目录

`rsync -rvl /opt/tmp/*  root@hadoop103:/opt/tmp`


### 3.3.6 编写集群分发脚本xsync

1）需求分析：循环复制文件到所有节点的相同目录下

（1）原始拷贝：

`rsync  -rvl     /opt/module  		 root@hadoop103:/opt/`

（2）期望脚本：

`  xsync 要同步的文件名称`

（3）在/usr/local/bin这个目录下存放的脚本，可以在系统任何地方直接执行，需要制定路径

2）案例实操：

（1）在/usr/local/bin目录下创建xsync文件，文件内容如下：

```
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
echo no args;
exit;
fi

#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
for((host=103; host<105; host++)); do
      #echo $pdir/$fname 0$user@hadoop$host:$pdir
      echo --------------- hadoop$host ----------------
      rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done

```

（2）修改脚本 xcall 具有执行权限

`[root@hadoop102 bin]# chmod a+x xcall`

（3）调用脚本形式： xcall 操作命令

`  [root@hadoop102 ~]# xcall rm -rf /opt/tmp/profile `

### 3.3.8 配置集群

1）集群部署规划



2）配置文件

（1）core-site.xml

```
<!-- 指定HDFS中NameNode的地址 -->
	<property>
		<name>fs.defaultFS</name>
        <value>hdfs://hadoop102:9000</value>
	</property>
	<!-- 指定hadoop运行时产生文件的存储目录 -->
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/opt/module/hadoop-2.7.2/data/tmp</value>
	</property>

```  

（2）Hdfs

hadoop-env.sh

`export JAVA_HOME=/opt/module/jdk1.7.0_79`

hdfs-site.xml

```
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
	<property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:50090</value>
    </property>
</configuration>

```

slaves

```
hadoop102
hadoop103
hadoop104

```

（3）yarn

  yarn-env.sh

`export JAVA_HOME=/opt/module/jdk1.7.0_79`

  yarn-site.xml

  ```
  <configuration>
  <!-- Site specific YARN configuration properties -->
  <!-- reducer获取数据的方式 -->
      <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
      </property>

  <!-- 指定YARN的ResourceManager的地址 -->
  	<property>
  		<name>yarn.resourcemanager.hostname</name>
  		<value>hadoop103</value>
  	</property>
  	</configuration>

  ```

  （4）mapreduce

  mapred-env.sh

  `export JAVA_HOME=/opt/module/jdk1.7.0_79`

  mapred-site.xml

```
<configuration>
<!-- 指定mr运行在yarn上 -->
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	</configuration>

```

3）在集群上分发以上所有文件

```
cd /opt/module/hadoop-2.7.2/etc/hadoop
xsync /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml
xsync /opt/module/hadoop-2.7.2/etc/hadoop/yarn-site.xml
xsync /opt/module/hadoop-2.7.2/etc/hadoop/slaves

```

4）查看文件分发情况

`	xcall cat /opt/module/hadoop-2.7.2/etc/hadoop/slavesv`

### 3.3.9 集群启动及测试

1）启动集群

（0）如果集群是第一次启动，需要格式化namenode

`[root@hadoop102 hadoop-2.7.2]# bin/hdfs namenode -format`

（1）启动HDFS：
```
[root@hadoop102 hadoop-2.7.2]# sbin/start-dfs.sh
[root@hadoop102 hadoop-2.7.2]# jps
4166 NameNode
4482 Jps
4263 DataNode

[root@hadoop103 桌面]# jps
3218 DataNode
3288 Jps

[root@hadoop104 桌面]# jps
3221 DataNode
3283 SecondaryNameNode
3364 Jps

```


（2）启动yarn

`sbin/start-yarn.sh`

tips: Namenode和ResourceManger如果不是同一台机器，不能在NameNode上启动 yarn，应该在ResouceManager所在的机器上启动yarn

2）集群基本测试

（1）上传文件到集群

上传小文件
```
bin/hdfs dfs -mkdir -p /user/atguigu/tmp/conf

bin/hdfs dfs -put etc/hadoop/*-site.xml /user/atguigu/tmp/conf

```
上传大文件
```
[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz  /user/atguigu/input

```

（2）上传文件后查看文件存放在什么位置

文件存储路径

```
[atguigu@hadoop102 subdir0]$ pwd
/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0

```
查看文件内容
```
[atguigu@hadoop102 subdir0]$ cat blk_1073741825
hadoop
atguigu
atguigu

```
（3）拼接
```
-rw-rw-r--. 1 atguigu atguigu 134217728 5月  23 16:01 blk_1073741836
-rw-rw-r--. 1 atguigu atguigu   1048583 5月  23 16:01 blk_1073741836_1012.meta
-rw-rw-r--. 1 atguigu atguigu  63439959 5月  23 16:01 blk_1073741837
-rw-rw-r--. 1 atguigu atguigu    495635 5月  23 16:01 blk_1073741837_1013.meta

```
```
[atguigu@hadoop102 subdir0]$ cat blk_1073741836>>tmp.file
[atguigu@hadoop102 subdir0]$ cat blk_1073741837>>tmp.file
[atguigu@hadoop102 subdir0]$ tar -zxvf tmp.file

```

（4）下载
```
[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -get /user/atguigu/input/hadoop-2.7.2.tar.gz
```

3）性能测试集群

写海量数据

读海量数据

### 3.3.10 Hadoop启动停止方式

1）各个服务组件逐一启动

（1）分别启动hdfs组件
```
	hadoop-daemon.sh  start|stop namenode|datanode|secondarynamenode
```

（2）启动yarn

`	yarn-daemon.sh  start|stop  resourcemanager|nodemanager`

2）各个模块分开启动（配置ssh是前提）常用

（1）整体启动/停止hdfs
```
	start-dfs.sh
	stop-dfs.sh
  ```

（2）整体启动/停止yarn
```
	start-yarn.sh
	stop-yarn.sh
  ```

### 3.3.11 配置集群常见问题

1）防火墙没关闭、或者没有启动yarn

INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032

2）主机名称配置错误

3）ip地址配置错误

4）ssh没有配置好

5）root用户和atguigu两个用户启动集群不统一

6）配置文件修改不细心

7）未编译源码
```
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/22 15:38:58 INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032
```
8）datanode不被namenode识别问题

Namenode在format初始化的时候会形成两个标识，blockPoolId和clusterId。新的datanode加入时，会获取这两个标识作为自己工作目录中的标识。
一旦namenode重新format后，namenode的身份标识已变，而datanode如果依然持有原来的id，就不会被namenode识别

解决办法，删除datanode节点中的数据后，再次重新格式化namenode

9）不识别主机名称

```
java.net.UnknownHostException: hadoop102: hadoop102
        at java.net.InetAddress.getLocalHost(InetAddress.java:1475)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:146)
        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)

```

解决办法：

（1）在/etc/hosts文件中添加192.168.1.102 hadoop102

（2）主机名称不要起hadoop  hadoop000等特殊名称

10）datanode和namenode进程同时只能工作一个

图

11）执行命令	不生效，粘贴word中命令时，遇到-和长–没区分开。导致命令失效

解决办法：尽量不要粘贴word中代码

12）jps发现进程已经没有，但是重新启动集群，提示进程已经开启。原因是在linux的根目录下/tmp目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群
